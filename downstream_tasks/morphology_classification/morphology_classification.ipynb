{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mi3se\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xformers\\__init__.py\", line 57, in _is_triton_available\n",
      "    import triton  # noqa\n",
      "ModuleNotFoundError: No module named 'triton'\n",
      "c:\\Users\\mi3se\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dinov2\\layers\\swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "c:\\Users\\mi3se\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dinov2\\layers\\attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "c:\\Users\\mi3se\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dinov2\\layers\\block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "\n",
    "from astroclip.env import format_with_env\n",
    "from morphology_utils.models import train_eval_on_question\n",
    "from morphology_utils.plotting import plot_radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTROCLIP_ROOT = format_with_env(\"{ASTROCLIP_ROOT}\")\n",
    "\n",
    "# Load the data\n",
    "galaxy_zoo = Table.read(\n",
    "    f\"../../datasets/galaxy_zoo/gz5_decals_crossmatched_embeddings.h5\"\n",
    ")\n",
    "\n",
    "# Remove the galaxies with fewer than 3 votes\n",
    "galaxy_zoo = galaxy_zoo[galaxy_zoo[\"smooth-or-featured_total-votes\"] >= 3]\n",
    "\n",
    "# Get the embeddings\n",
    "X = {\n",
    "    \"AstroCLIP\": torch.tensor(galaxy_zoo[\"astroclip_embeddings\"]),\n",
    "    \"AstroDINO\": torch.tensor(galaxy_zoo[\"astrodino_embeddings\"]),\n",
    "    \"Stein\": torch.tensor(galaxy_zoo[\"stein_embeddings\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the columns\n",
    "names = names = [\n",
    "    \"smooth\",\n",
    "    \"disk-edge-on\",\n",
    "    \"spiral-arms\",\n",
    "    \"bar\",\n",
    "    \"bulge-size\",\n",
    "    \"how-rounded\",\n",
    "    \"edge-on-bulge\",\n",
    "    \"spiral-winding\",\n",
    "    \"spiral-arm-count\",\n",
    "    \"merging\",\n",
    "]\n",
    "\n",
    "# Get the labels\n",
    "galaxy_zoo.remove_columns(\n",
    "    [\"astroclip_embeddings\", \"astrodino_embeddings\", \"stein_embeddings\"]\n",
    ")\n",
    "classifications = galaxy_zoo\n",
    "\n",
    "# Get the key list\n",
    "keys = {\n",
    "    name: {\n",
    "        \"target\": [\n",
    "            key\n",
    "            for key in classifications.colnames\n",
    "            if name in key and \"debiased\" in key and \"mask\" not in key\n",
    "        ],\n",
    "        \"counts\": [\n",
    "            key\n",
    "            for key in classifications.colnames\n",
    "            if name in key and \"total-votes\" in key\n",
    "        ][0],\n",
    "    }\n",
    "    for name in names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 42\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(classifications)), test_size=0.2, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first 80% for train and last 20% for test\n",
    "# train_indices = int(0.8 * len(classifications))\n",
    "\n",
    "X_train, X_test = {}, {}\n",
    "for key in X.keys():\n",
    "    X_train[key] = X[key][train_indices]\n",
    "    X_test[key] = X[key][test_indices]\n",
    "\n",
    "classifications_train, classifications_test = (\n",
    "    classifications[train_indices],\n",
    "    classifications[test_indices],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2126, Test samples: 136\n",
      "Training on question: smooth...\n",
      "Model: AstroCLIP, Accuracy: 0.8309, F1: 0.8277\n",
      "Model: AstroDINO, Accuracy: 0.8676, F1: 0.8645\n",
      "Model: Stein, Accuracy: 0.8015, F1: 0.7961\n",
      "Done!\n",
      "Train samples: 2126, Test samples: 35\n",
      "Training on question: disk-edge-on...\n",
      "Model: AstroCLIP, Accuracy: 0.9143, F1: 0.8733\n",
      "Model: AstroDINO, Accuracy: 0.9143, F1: 0.8733\n",
      "Model: Stein, Accuracy: 0.9143, F1: 0.8733\n",
      "Done!\n",
      "Train samples: 2126, Test samples: 27\n",
      "Training on question: spiral-arms...\n",
      "Model: AstroCLIP, Accuracy: 0.8148, F1: 0.8314\n",
      "Model: AstroDINO, Accuracy: 0.8519, F1: 0.8519\n",
      "Model: Stein, Accuracy: 0.8519, F1: 0.8519\n",
      "Done!\n",
      "Train samples: 2126, Test samples: 27\n",
      "Training on question: bar...\n",
      "Model: AstroCLIP, Accuracy: 0.4444, F1: 0.2735\n",
      "Model: AstroDINO, Accuracy: 0.4444, F1: 0.2735\n",
      "Model: Stein, Accuracy: 0.4444, F1: 0.2735\n",
      "Done!\n",
      "Train samples: 2126, Test samples: 27\n",
      "Training on question: bulge-size...\n",
      "Model: AstroCLIP, Accuracy: 0.4444, F1: 0.2735\n",
      "Model: AstroDINO, Accuracy: 0.7407, F1: 0.7001\n",
      "Model: Stein, Accuracy: 0.7778, F1: 0.7495\n",
      "Done!\n",
      "Train samples: 2126, Test samples: 20\n",
      "Training on question: how-rounded...\n",
      "Model: AstroCLIP, Accuracy: 0.7000, F1: 0.7000\n",
      "Model: AstroDINO, Accuracy: 0.6000, F1: 0.5820\n",
      "Model: Stein, Accuracy: 0.3500, F1: 0.1815\n",
      "Done!\n",
      "Train samples: 2126, Test samples: 2\n",
      "Training on question: edge-on-bulge...\n",
      "Model: AstroCLIP, Accuracy: 0.5000, F1: 0.3333\n",
      "Model: AstroDINO, Accuracy: 0.5000, F1: 0.3333\n",
      "Model: Stein, Accuracy: 0.5000, F1: 0.3333\n",
      "Done!\n",
      "Train samples: 2126, Test samples: 23\n",
      "Training on question: spiral-winding...\n",
      "Model: AstroCLIP, Accuracy: 0.7826, F1: 0.6872\n",
      "Model: AstroDINO, Accuracy: 0.7826, F1: 0.6872\n",
      "Model: Stein, Accuracy: 0.7826, F1: 0.6872\n",
      "Done!\n",
      "Train samples: 2126, Test samples: 23\n",
      "Training on question: spiral-arm-count...\n",
      "Model: AstroCLIP, Accuracy: 0.3913, F1: 0.3540\n",
      "Model: AstroDINO, Accuracy: 0.4348, F1: 0.3889\n",
      "Model: Stein, Accuracy: 0.4783, F1: 0.4178\n",
      "Done!\n",
      "Train samples: 2126, Test samples: 95\n",
      "Training on question: merging...\n",
      "Model: AstroCLIP, Accuracy: 0.7368, F1: 0.6197\n",
      "Model: AstroDINO, Accuracy: 0.7368, F1: 0.6197\n",
      "Model: Stein, Accuracy: 0.7368, F1: 0.6197\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# This is the total number of possible votes\n",
    "total_counts_train = classifications_train[keys[\"smooth\"][\"counts\"]].data\n",
    "\n",
    "# Get accuracy and F1 score on each question\n",
    "outputs = {key: {} for key in X.keys()}\n",
    "for name in names:\n",
    "    question, num_classes = name, len(keys[name][\"target\"])\n",
    "\n",
    "    # Get the train samples above 50% answered\n",
    "    counts_train = classifications_train[keys[name][\"counts\"]].data\n",
    "    # train_mask = np.where(counts_train / total_counts_train > 0.5)[0]\n",
    "    train_mask = [True] * len(counts_train)\n",
    "\n",
    "    # Get the test samples above 34 answers\n",
    "    counts_test = classifications_test[keys[name][\"counts\"]].data\n",
    "    test_mask = np.where(counts_test > 34)[0]\n",
    "\n",
    "    # Get train and test\n",
    "    y_train = torch.tensor(\n",
    "        classifications_train[keys[name][\"target\"]].to_pandas().values\n",
    "    )[train_mask]\n",
    "    y_test = torch.tensor(\n",
    "        classifications_test[keys[name][\"target\"]].to_pandas().values\n",
    "    )[test_mask]\n",
    "    \n",
    "    print(f\"Train samples: {y_train.shape[0]}, Test samples: {y_test.shape[0]}\")\n",
    "    \n",
    "    if y_train.shape[0] == 0 or y_test.shape[0] == 0:\n",
    "        print(f\"Skipping {question}. Not enough samples.\")\n",
    "        continue\n",
    "\n",
    "    train_nan_mask = torch.isnan(y_train).any(axis=1)\n",
    "    test_nan_mask = torch.isnan(y_test).any(axis=1)\n",
    "\n",
    "    # Train and evaluate on each model\n",
    "    print(f\"Training on question: {question}...\")\n",
    "    for model in X.keys():\n",
    "        X_train_local = X_train[model][train_mask][~train_nan_mask]\n",
    "        X_test_local = X_test[model][test_mask][~test_nan_mask]\n",
    "        outputs[model][name] = train_eval_on_question(\n",
    "            X_train_local,\n",
    "            X_test_local,\n",
    "            y_train,\n",
    "            y_test,\n",
    "            X_train_local.shape[1],\n",
    "            num_classes=num_classes,\n",
    "            MLP_dim=256,\n",
    "            epochs=25,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        print(\n",
    "            f\"Model: {model}, Accuracy: {outputs[model][name]['Accuracy']:.4f}, F1: {outputs[model][name]['F1 Score']:.4f}\"\n",
    "        )\n",
    "    print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up labels\n",
    "outputs[\"Unaligned Transformer\"] = outputs.pop(\"AstroDINO\")\n",
    "outputs[\"Stein, et al.\"] = outputs.pop(\"Stein\")\n",
    "\n",
    "# Plot radar plots\n",
    "plot_radar(outputs, metric=\"Accuracy\", file_path=f\"./outputs/radar_accuracy.png\")\n",
    "plot_radar(outputs, metric=\"F1 Score\", file_path=f\"./outputs/radar_f1_score.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
